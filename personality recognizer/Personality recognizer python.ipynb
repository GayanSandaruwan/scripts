{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "print(subprocess.Popen(\"echo Hello World\", shell=True, stdout=subprocess.PIPE).stdout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdk_path = subprocess.Popen(\"echo %JAVA_HOME%\", shell=True, stdout=subprocess.PIPE).stdout.readline()    # to make sure jdk path is set\n",
    "print(jdk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weka_path=\"weka-3-4\\weka.jar\"                    # don't change these unless you changed the location of these folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMONS_CLI=\"lib\\commons-cli-1.0.jar\"            # don't change these unless you changed the location of these folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "JMRC=\"lib\\jmrc.jar\"                              # don't change these unless you changed the location of these folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "appDir = \"E:\\CiperLabs\\\\fiver\\scripts\\personality recognizer\\PersonalityRecognizer\"     #Directory where the java application is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIBS=weka_path+\";\"+COMMONS_CLI+\";\"+JMRC+\";\"+'bin\\\\'     #+appDir+\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class cd:\n",
    "    \"\"\"Context manager for changing the current working directory\"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the properties here to change the model parameters and files\n",
    "\n",
    "\n",
    "# -d,--directory\t\tCorpus analysis mode. Input must be a directory with \n",
    "#                          multiple text files, features are standardized over \n",
    "#                          the corpus and the recognizer outputs a personality \n",
    "#                          estimate for each text file.\n",
    "\n",
    "input_type_is_dir = \"-d\"  #(\"set \"-d\" if folder or \"\" if file\")\n",
    "\n",
    "# -i,--input       \tInput file or directory (required)\n",
    "input_file_folder = \"examples\" \n",
    "\n",
    "#-m,--model       \tModel to use for computing scores (default 4). Options:\n",
    "#  \t              \t\t\t\t1 = Linear Regression\n",
    "#                \t\t\t\t2 = M5' Model Tree\n",
    "#              \t\t\t\t\t3 = M5' Regression Tree\n",
    "#              \t\t\t\t\t4 = Support Vector Machine with Linear Kernel (SMOreg)\n",
    "\n",
    "model = \"3\" \n",
    "\n",
    "# -t,--type\t\tSelects the type of model to use (default 1). The appropriate\n",
    "#                         \t\tmodel depends on the language sample (written or \n",
    "#   \t\t\t\t\tspoken), and whether observed personality (as perceived \n",
    "#   \t\t\t\t\tby external judges) or self-assessed personality (the \n",
    "#   \t\t\t\t\twriter/speaker's perception) needs to be estimated from the \n",
    "#   \t\t\t\t\ttext. Options:\n",
    "#   \t\t\t\t\t\t1 = Observed personality from spoken language\n",
    "#                                 \t\t2 = Self-assessed personality from written language\n",
    "model_type = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execPR():\n",
    "    output = []\n",
    "    # enter the app directory\n",
    "    with cd(appDir):\n",
    "       # we are in app directory when exiting the block we exit from the directory\n",
    "        command = 'java -Xmx512m -classpath '+ LIBS+ ' recognizer.PersonalityRecognizer '+ input_type_is_dir + ' -i '+input_file_folder + ' -m '+model+' -t '+model_type\n",
    "        p = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        print(command)\n",
    "        for line in p.stdout.readlines():\n",
    "            output.append(line.decode(\"utf-8\"))\n",
    "        retval = p.wait()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -Xmx512m -classpath weka-3-4\\weka.jar;lib\\commons-cli-1.0.jar;lib\\jmrc.jar;bin\\ recognizer.PersonalityRecognizer -d -i examples -m 3 -t 2\n"
     ]
    }
   ],
   "source": [
    "outputstream = execPR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LIWC dictionary loaded (68 lexical categories)\\r\\n', 'Loading MRC Psycholinguistic Database...\\r\\n', '120038 words loaded.\\r\\n', 'Loading model E:\\\\CiperLabs\\\\fiver\\\\scripts\\\\personality recognizer\\\\PersonalityRecognizer\\\\lib\\\\models\\\\self\\\\M5P-R\\\\std-extra.model...\\r\\n', 'Loading model E:\\\\CiperLabs\\\\fiver\\\\scripts\\\\personality recognizer\\\\PersonalityRecognizer\\\\lib\\\\models\\\\self\\\\M5P-R\\\\std-ems.model...\\r\\n', 'Loading model E:\\\\CiperLabs\\\\fiver\\\\scripts\\\\personality recognizer\\\\PersonalityRecognizer\\\\lib\\\\models\\\\self\\\\M5P-R\\\\std-agree.model...\\r\\n', 'Loading model E:\\\\CiperLabs\\\\fiver\\\\scripts\\\\personality recognizer\\\\PersonalityRecognizer\\\\lib\\\\models\\\\self\\\\M5P-R\\\\std-consc.model...\\r\\n', 'Loading model E:\\\\CiperLabs\\\\fiver\\\\scripts\\\\personality recognizer\\\\PersonalityRecognizer\\\\lib\\\\models\\\\self\\\\M5P-R\\\\std-open.model...\\r\\n', 'Reading directory E:\\\\CiperLabs\\\\fiver\\\\scripts\\\\personality recognizer\\\\PersonalityRecognizer\\\\examples...\\r\\n', '\\r\\n', 'Computing features for file Amy.txt...\\r\\n', 'Input text splitted into 551 words and 36 sentences\\r\\n', 'LIWC features computed: 70\\r\\n', 'MRC features computed: 14\\r\\n', 'Warning: feature BROWN-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NCATS has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NSAMP has no value, setting as missing...\\r\\n', 'Warning: feature T-L-FREQ has no value, setting as missing...\\r\\n', '\\r\\n', 'Computing features for file John.txt...\\r\\n', 'Input text splitted into 808 words and 67 sentences\\r\\n', 'LIWC features computed: 70\\r\\n', 'MRC features computed: 14\\r\\n', 'Warning: feature BROWN-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NCATS has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NSAMP has no value, setting as missing...\\r\\n', 'Warning: feature T-L-FREQ has no value, setting as missing...\\r\\n', '\\r\\n', 'Computing features for file Matt.txt...\\r\\n', 'Input text splitted into 322 words and 11 sentences\\r\\n', 'LIWC features computed: 70\\r\\n', 'MRC features computed: 14\\r\\n', 'Warning: feature BROWN-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NCATS has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NSAMP has no value, setting as missing...\\r\\n', 'Warning: feature T-L-FREQ has no value, setting as missing...\\r\\n', '\\r\\n', 'Computing features for file Rob.txt...\\r\\n', 'Input text splitted into 467 words and 22 sentences\\r\\n', 'LIWC features computed: 70\\r\\n', 'MRC features computed: 14\\r\\n', 'Warning: feature BROWN-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-FREQ has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NCATS has no value, setting as missing...\\r\\n', 'Warning: feature K-F-NSAMP has no value, setting as missing...\\r\\n', 'Warning: feature T-L-FREQ has no value, setting as missing...\\r\\n', 'Computing standardized values for each feature over the whole corpus (4 files)\\r\\n', '\\r\\n', '\\r\\n', \"Output of M5' Regression Tree:\\r\\n\", '------------------------------\\r\\n', '\\r\\n', '\\r\\n', '\\r\\n', 'Estimates of self-assessed personality for each file, using standardized features:\\r\\n', '\\r\\n', 'File              \\tExtra\\tEmoti\\tAgree\\tConsc\\tOpenn\\r\\n', 'Amy.txt          \\t4.711\\t3.585\\t4.493\\t4.793\\t4.973\\r\\n', 'John.txt         \\t5.132\\t4.388\\t4.535\\t4.333\\t4.496\\r\\n', 'Matt.txt         \\t4.796\\t3.585\\t4.285\\t4.893\\t4.253\\r\\n', 'Rob.txt          \\t4.678\\t4.213\\t4.493\\t4.82\\t4.681\\r\\n', '\\r\\n', '\\r\\n', 'Extra = Extraversion\\r\\n', 'Emoti = Emotional stability\\r\\n', 'Agree = Agreeableness\\r\\n', 'Consc = Conscientiousness\\r\\n', 'Openn = Openness to experience\\r\\n', '\\r\\n', 'Models are trained to output scores on a scale from 1 (low) to 7 (high),\\r\\n', 'the scores might need to be normalized depending on the application domain.\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "print(outputstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amy.txt\n",
      "John.txt\n",
      "Matt.txt\n",
      "Rob.txt\n"
     ]
    }
   ],
   "source": [
    "output=[]                 #{filename,textprop,LIWC,MRC,extra,emoti,agree,consc,openn}\n",
    "results = []\n",
    "outStarted = False\n",
    "for line in outputstream:\n",
    "    if(line.startswith(\"Computing features for file\")):\n",
    "        name = line[28:][:-5]\n",
    "        out = {}\n",
    "        out[\"name\"] =name\n",
    "        index_of_arr = outputstream.index(line)\n",
    "        out[\"textprop\"] = outputstream[index_of_arr+1][:-2]\n",
    "        out[\"LIWC\"] =outputstream[index_of_arr+2][:-2]\n",
    "        out[\"MRC\"] = outputstream[index_of_arr+3][:-2]\n",
    "        output.append(out)\n",
    "        print(name)\n",
    "    elif(line.startswith(\"File              \\tExtra\\tEmoti\\tAgree\\tConsc\\tOpenn\\r\\n\")):\n",
    "        outStarted = True\n",
    "    elif(line.startswith(\"\\r\\n\")):\n",
    "        outStarted = False\n",
    "    elif(outStarted):\n",
    "        results.append(line[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(output)):\n",
    "    res = results[i].split(\t)                # Splitting by tab\n",
    "    output[i][\"extra\"] = res[1]\n",
    "    output[i][\"emoti\"] = res[2]\n",
    "    output[i][\"agree\"] = res[3]\n",
    "    output[i][\"consc\"] = res[4]\n",
    "    output[i][\"openn\"] = res[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Amy.txt',\n",
       "  'textprop': 'Input text splitted into 551 words and 36 sentences',\n",
       "  'LIWC': 'LIWC features computed: 70',\n",
       "  'MRC': 'MRC features computed: 14',\n",
       "  'extra': '4.64',\n",
       "  'emoti': '3.682',\n",
       "  'agree': '4.697',\n",
       "  'consc': '4.614',\n",
       "  'openn': '4.746'},\n",
       " {'name': 'John.txt',\n",
       "  'textprop': 'Input text splitted into 808 words and 67 sentences',\n",
       "  'LIWC': 'LIWC features computed: 70',\n",
       "  'MRC': 'MRC features computed: 14',\n",
       "  'extra': '4.865',\n",
       "  'emoti': '4.219',\n",
       "  'agree': '4.747',\n",
       "  'consc': '4.633',\n",
       "  'openn': '4.694'},\n",
       " {'name': 'Matt.txt',\n",
       "  'textprop': 'Input text splitted into 322 words and 11 sentences',\n",
       "  'LIWC': 'LIWC features computed: 70',\n",
       "  'MRC': 'MRC features computed: 14',\n",
       "  'extra': '4.764',\n",
       "  'emoti': '3.24',\n",
       "  'agree': '4.571',\n",
       "  'consc': '4.788',\n",
       "  'openn': '5.095'},\n",
       " {'name': 'Rob.txt',\n",
       "  'textprop': 'Input text splitted into 467 words and 22 sentences',\n",
       "  'LIWC': 'LIWC features computed: 70',\n",
       "  'MRC': 'MRC features computed: 14',\n",
       "  'extra': '4.858',\n",
       "  'emoti': '4.727',\n",
       "  'agree': '4.559',\n",
       "  'consc': '5.038',\n",
       "  'openn': '4.188'}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
